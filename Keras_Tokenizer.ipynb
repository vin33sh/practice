{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Tokenizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnkVhLOhryFBkyiXe9TJgL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vin33sh/practice/blob/main/Keras_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Keras Optimizer**"
      ],
      "metadata": {
        "id": "CiCyIbNA0vtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this practice session, we will explore Keras tokenizer through which we will convert the texts into sequences that can be further fed to the predictive model. To do this we will make use of the Reuters data set that can be directly imported from the Keras library or can be downloaded from Kaggle. This data set contains  11,228 newswires from Reuters having 46 topics as labels. We will make use of different modes present in Keras tokenizer and will build deep neural networks for classification."
      ],
      "metadata": {
        "id": "npiCYRMo03BB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0p8cfk50r0x"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}